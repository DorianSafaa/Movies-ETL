# Movies-ETL

<<<<<<< HEAD
##Background

In this project, we automated a pipeline that takes in new data, performs the appropriate transformations, and loads the data into existing tables. We used an existing code to create one function that takes in the three files—Wikipedia data, Kaggle metadata, and the MovieLens rating data—and performs the ETL process by adding the data to a PostgreSQL database.
=======
## Background

In this project, we automated a pipeline that takes in new data, performs the appropriate transformations, and loads the data into existing tables. We used an existing code to create one function that takes in the three filesâ€”Wikipedia data, Kaggle metadata, and the MovieLens rating dataâ€”and performs the ETL process by adding the data to a PostgreSQL database.
>>>>>>> 0d2de8e12d3f7a078f53d84842a584f6fde7cbe8

## About the analysis

This project consists of four technical analysis deliverables:

Deliverable 1: Write an ETL Function to Read Three Data Files
Deliverable 2: Extract and Transform the Wikipedia Data
Deliverable 3: Extract and Transform the Kaggle data
Deliverable 4: Create the Movie Database

## Resources

Data source: Wikipedia JSON file and Kaggle CSV files.
Data tools: PgAdmin/PostgreSQL and Jupyter Notebook/Python
<<<<<<< HEAD


=======
>>>>>>> 0d2de8e12d3f7a078f53d84842a584f6fde7cbe8
